(window.webpackJsonp=window.webpackJsonp||[]).push([[189],{575:function(a,v,_){"use strict";_.r(v);var t=_(54),s=Object(t.a)({},(function(){var a=this,v=a.$createElement,_=a._self._c||v;return _("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[_("h1",{attrs:{id:"数据工程和机器学习"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据工程和机器学习"}},[a._v("#")]),a._v(" 数据工程和机器学习")]),a._v(" "),_("p",[a._v("在互联网和数宇化时代，世界各地都在以飞快的速度产生大量的数据。如何从这些海量数据中快速获得洞见是一个挑战。我们需要不断创新以采集、存储和处理这些数据，从而产生业务成果。")]),a._v(" "),_("p",[a._v("随着云技术、移动技术和社交技术的融合，基因组学和生命科学等众多领域正在以越来越快的速度发展。通过挖掘数据来获得更多的洞见呈现出巨大的价值。流处理系统与批处理系统的一个根本区别是能否处理无限数据。现代流处理系统需要以低延迟的方式处理高速且流入速率可变的数据，并持续产生结果。")]),a._v(" "),_("p",[a._v("大数据的概念不仅仅包含数据的收集和分析。对于组织来说，数据的实际价值是它可以用来回答问题，并为组织创造竞争优势。并非所有的大数据解决方案都必须以可视化结果为终点。许多解决方案如机器学习 (Machine Learning， ML) 和预测分析，将这些答案以编程的方式反馈到其他软件或应用程序，这些软件或应用程序从答案中提取信息，并按照设计的方式进行响应。")]),a._v(" "),_("p",[a._v("与大多数事情一样，越快获得结果，就需要越高的成本，大数据也不例外。有些答案可能不是立即需要的，因此，解决方案的延迟和吞吐量可以灵活地放宽到数小时内完成。其他的响应（例如在预测分析或机器学习领域）可能需要在数据可用时尽快完成。")]),a._v(" "),_("h2",{attrs:{id:"大数据架构"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#大数据架构"}},[a._v("#")]),a._v(" 大数据架构")]),a._v(" "),_("p",[a._v("随着越来越多数据的积累，管理和迁移数据及其底层大数据基础设施变得越来越困难，收集到的海量数据可能也会造成新的问题，在数据架构中，数据流水线一般以数据为起点，以洞见为终点，大数据流水线的标准工作流程包括以下步骤：\n"),_("img",{attrs:{src:"https://i.bmp.ovh/imgs/2022/06/04/461e15eb41860b7b.png",alt:""}})]),a._v(" "),_("ol",[_("li",[a._v("通过合适的工具采集数据。")]),a._v(" "),_("li",[a._v("持久化存储数据。")]),a._v(" "),_("li",[a._v("数据处理或分析。从存储中获取数据，并对其进行操作，然后将处理后的数据再次存储。")]),a._v(" "),_("li",[a._v("数据被其他处理/分析工具使用，或者被同一工具再次处理，从数据中获得进一步结果。")]),a._v(" "),_("li",[a._v("为了使结果对业务用户有作用，使用BI工具将结果可视化，或者将结果输入机器学习算法中进行预测。")]),a._v(" "),_("li",[a._v("将合理的结果呈现给用户，就为他们提供了对数据的洞见，用户可以采用这些数据进行进一步的业务决策。")])]),a._v(" "),_("h2",{attrs:{id:"大数据处理流水线设计"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#大数据处理流水线设计"}},[a._v("#")]),a._v(" 大数据处理流水线设计")]),a._v(" "),_("p",[a._v("许多大数据架构经常犯的关键性错误之一是，试图用一个工具包办数据流水线的多个阶段的数据处理。用一个服务器集群来端到端的处理数据存储、转换到数据可视化的整个流程可能是最简单的，但是它也最容易发生故障。建议做解决方案架构时对数据流水线进行解耦，特别是将存储和处理分为多个阶段，这样可以提高容错能力。下图是设计大数据架构流水线时需要考虑的各种工具和流程：")]),a._v(" "),_("p",[_("img",{attrs:{src:"https://i.bmp.ovh/imgs/2022/06/04/671830e22e7fe0e1.png",alt:""}})]),a._v(" "),_("p",[a._v("在为大数据架构进行选型时，应该考虑数据结构、最大可接受延迟、最低可接受吞吐量、重点用户的典型访问模式等内容。数据结构会影响数据处理工具以及存储位置的选择，获得结果的时间取决于解决方案如何权衡延迟、吞吐量和成本。有些作业需要定期快速连接许多相关的表，有些作业则需要每天或按更低频率使用存储的数据，有些作业需要比较来自各种数据源的数据，而有些作业只需要从一个非结构化表中提取数据，了解终端用户最常使用数据的方式将有助于确定大数据架构的广度和深度。")]),a._v(" "),_("h2",{attrs:{id:"数据采集"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据采集"}},[a._v("#")]),a._v(" 数据采集")]),a._v(" "),_("p",[a._v("数据采集是指数据传输和存储前的数据收集过程，数据来源众多，主要采集自数据库、流、日志和文件。其中，数据库是最主要的数据来源，这些数据通常包括上游核心事务系统，应用程序的主要数据保存在这里。流是事件序列数据的无线序列，如来自网站或物联网设备的点击流数据，通常会发布到托管的API中。日志由应用程序、服务和操作系统产生。文件可能来自自建的文件系统，也可以通过FTP或第三方API获得。")]),a._v(" "),_("p",[_("img",{attrs:{src:"https://i.bmp.ovh/imgs/2022/06/05/28a37cd6823bb110.png",alt:""}})]),a._v(" "),_("p",[a._v("流行的数据采集的工具如下：")]),a._v(" "),_("ul",[_("li",[_("strong",[a._v("Apache DistCp")]),a._v("：DistCp代表分布式拷贝（distributed copy），是Hadoop生态系统的一部分，DistCp工具用在集群内或集群间复制大型数据。DistCp利用MapReduce自带的影响处理分发能力实现数据的高效快速复制。它将目录和文件分发到映射任务中，将文件分区从源端复制到目标端。DistCp还可以跨集群进行错误处理、恢复和报告。")]),a._v(" "),_("li",[_("strong",[a._v("Apache Sqoop")]),a._v("：Sqoop也来自Hadoop生态，它帮助在Hadoop和关系型数据存储之间传输数据，Sqoop可以让我们将结构化数据存储导入Hadoop分布式文件系统（Hadoop Distributed File System，HDFS），并将数据从HDFS导出到结构化数据存储。Sqoop使用插件连接器连接到关系型数据库，我们可以使用Sqoop扩展API构建新的连接器，也可以使用内置连接器来支持Hadoop和常见关系型数据库之间的数据交换。")]),a._v(" "),_("li",[_("strong",[a._v("Apache Kafka")]),a._v("：Kafka是最流行的开源数据处理平台之一，可以帮助我们发布和订阅数据流。Kafka集群将记录的流存储在Kafka主题中。生产者可以在Kafka主题中发布数据，消费者可以通过订阅Kafka主题来获取输出的数据流。")]),a._v(" "),_("li",[_("strong",[a._v("Apache Flume")]),a._v("：Flume主要用于采集大量日志数据，它以分布式的方式可靠的将数据收集、汇总到Hadoop，Flume有利于流数据的采集，并可以进行分析。")]),a._v(" "),_("li",[_("strong",[a._v("Apache Flink")]),a._v("：Flink包括一个流数据引擎，可以处理有界和无界的数据流，有界数据流有确定的开端和结尾，无界数据流有开端但是没结尾，Flink也可以在流数据引擎上进行批处理，并支持批处理优化。")])]),a._v(" "),_("h2",{attrs:{id:"数据存储"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据存储"}},[a._v("#")]),a._v(" 数据存储")]),a._v(" "),_("p",[a._v("在为大数据环境搭建存储时，理想的存储解决方案是使用合适的工具完成相应的作业，数据存储的选择取决于多种因素，我们要根据数据的结构、数据的更新处理频率、采集数据的规模、数据的增长速度等因素来进行综合设计。确定了数据的特性并了解数据结构后，才可以评估数据存储需要哪种解决方案。")]),a._v(" "),_("p",[_("img",{attrs:{src:"https://i.bmp.ovh/imgs/2022/06/06/e3239739cb6300b4.png",alt:""}})]),a._v(" "),_("h3",{attrs:{id:"数据存储的可选技术"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据存储的可选技术"}},[a._v("#")]),a._v(" 数据存储的可选技术")]),a._v(" "),_("p",[_("strong",[a._v("结构化数据存储")]),a._v("是人们最熟悉的存储技术，因为要处理频繁的数据写入，大多数事务型数据库都是行式数据库，基于行的写入方式是将数据写入磁盘最快的方式，但它不一定能最快的读取，基于列的格式将列值存储在文件中会带来更好的压缩效果。")]),a._v(" "),_("p",[a._v("传统的"),_("strong",[a._v("关系型数据库")]),a._v("就是行式数据库的代表，它们比较适合在线事务处理，比较流行的有Oracle、MySQL、PostgreSQL等等。关系型数据非常擅长处理需要复杂联合查询的事务数据，关系型数据库的使用有如下几点原则：")]),a._v(" "),_("ul",[_("li",[a._v("原子性：事务将从头到尾完全执行，一旦出现错误，整个事务将会回滚。")]),a._v(" "),_("li",[a._v("一致性：一旦事务完成，所有的数据都要提交到数据库中。")]),a._v(" "),_("li",[a._v("隔离性：要求多个事务能在隔离的情况下同时运行，互不干扰。")]),a._v(" "),_("li",[a._v("持久性：在任何中断的情况下。事务应该能够恢复到最后已知的状态。")])]),a._v(" "),_("p",[a._v("通常情况下，关系型数据库的数据会被转存到数据仓库中，用于报表和聚合。"),_("strong",[a._v("数据仓库")]),a._v("更适合在线分析处理应用。数据仓库提供了对海量结构化数据的快速聚合功能，现代的数据仓库使用列式存储来提升查询性能，得益于列式存储，数据仓库可以有非常快的查询速度。数据仓库是中央存储库，可以存储来自一个或多个数据库累积的数据，它们存储当前和历史数据，用于创建业务数据的分析报告。")]),a._v(" "),_("p",[_("strong",[a._v("NoSQL数据库")]),a._v("可以解决在关系型数据库中经常遇到的伸缩和性能的挑战，NoSQL数据库存储的数据没有明确的结构机制连接不同表中的数据。NoSQL运用了多种数据模型，包括列式、键值、搜索、文档和图模型，它没有严格的数据库模式，每条记录都可以有任意数量的列，分区键用于检索包含相关属性的值或文档，下图是NoSQL数据库和关系型数据库的区别：")]),a._v(" "),_("p",[_("img",{attrs:{src:"https://i.bmp.ovh/imgs/2022/06/06/5572a2e0cf0fcc7f.png",alt:""}})]),a._v(" "),_("p",[_("strong",[a._v("NoSQL数据库只要有如下几种类型")]),a._v("：")]),a._v(" "),_("ul",[_("li",[a._v("列式数据库：Apache Cassandra 和Apache HBase是流行的列式数据库。列式数据存储有助于在查询数据时扫描某一列，而不是扫描整行。如果物品表有10列100万行，而你想查询库存中某一物品的数量，那么列式数据库只会将查询应用于物品数量列，不需要扫描整个表。")]),a._v(" "),_("li",[a._v("文档数据库：最流行的文档数据库有MongoDB、Couchbase、MarkLogic、 Dynamo DB。可以使用文档数据库来存储JSON和XML格式的半结构化数据。")]),a._v(" "),_("li",[a._v("图数据库：流行的图数据库包括Amazon Neptune、JanusGraph、 TinkerPop、Neo4j、OrientDB、GraphDB和Spark上的GraphX。图数据库存储顶点和顶点之间的链接（称为边）。图可以建立在关系型和非关系型数据库上。")]),a._v(" "),_("li",[a._v("内存式键值存储：最流行的内存式键值存储是Redis和Memcached。它们将数据存储在内存中，用于数据读取频率高的场景。应用程序的查询首先会转到内存数据库，如果数据在缓存中可用，则不会冲击主数据库。内存数据库很适合存储用户会话信息，这些数据会导致复杂的查询和频繁的请求数据。")])]),a._v(" "),_("p",[_("strong",[a._v("Elasticsearch")]),a._v("是大数据场景 （如点击流和日志分析） 最受欢迎的搜索引擎之一。搜索引擎能很好地支持对具有任意数量的属性（包括字符\n串令牌）的数据进行临时查询。Elasticsearch可以帮助我们分析来自网站、服务器、物联网传感器的日志数据。")]),a._v(" "),_("h2",{attrs:{id:"数据处理和分析"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据处理和分析"}},[a._v("#")]),a._v(" 数据处理和分析")]),a._v(" "),_("p",[a._v("数据分析是对数据进行ETL的过程，用来发掘对业务决策有用的洞见。")]),a._v(" "),_("p",[_("img",{attrs:{src:"https://i.bmp.ovh/imgs/2022/06/06/22e1d536fddd061c.png",alt:""}})]),a._v(" "),_("p",[a._v("如图，从各种数据源采集的数据都存储在S3中，ETL流水线可以使用Athena对存储在S3中的数据进程查询，这些文件被Amazon Elastic MapReduce（EMR）转换和清洗成所需形式后，再加载到S3中。用copy命令将转换后的文件加载到Redshift，并使用QuickSight进行可视化。")]),a._v(" "),_("p",[a._v("下面是一些流行的数据转换和处理的技术：")]),a._v(" "),_("ul",[_("li",[_("strong",[a._v("Apache Hadoop")]),a._v("使用分布式处理架构，将任务分发到服务器集群上进行处理。分发到集群服务器上的每一项任务都可以在任意一台服务器上运行或重新运行。集群服务器通常使用HDFS将数据存储到本地进行处理。在Hadoop框架中，Hadoop将大的作业分割成离散的任务，并行处理。它能在数量庞大的Hadoop集群中实现大规模的伸缩性。它还设计了容错功能，每个工作节点都会定期向主节点报告自己的状态，主节点可以将工作负载从没有积极响应的集群重新分配出去。Hladoop最常用的框架有Hive、Presto、Pig和Spark。")]),a._v(" "),_("li",[_("strong",[a._v("Apache Spark")]),a._v("是一个内存处理框架。Apache Spark是一个大规模并行处理系统，它有不同的执行器，可以将Spark作业拆分，并行执行任务。为了提高作业的并行度，可以在集群中增加节点。Spark支持批处理、交互式和流式数据源。Spark在作业执行过程中的所有阶段都使用有向无环图 ( Directed Acyclic Graph, DAG)。DAC可以跟踪作业过程中数据的转换或数据沿袭情况，并将DataFrames存储在内存中有效地最小化I/O。Spark还具有分区感知功能，以避免网络密集型的数据改组。")]),a._v(" "),_("li",[_("strong",[a._v("Pig")]),a._v("用于处理大量的原始数据，然后再以结构化格式（SQL表）存储。Pig适用于ETL操作，如数据验证、数据加载、数据转换，以及以多种格式组合来自多个来源的数据。除了ETL，Pig还支持关系操作，如嵌套数据、连接和分组。Pig脚本可以使用非结构化和半结构化数据（如Web服务器日志或点击流日志） 作为输入。")]),a._v(" "),_("li",[_("strong",[a._v("Hive")]),a._v("是一个开源的数据仓库和查询包，运行在Hadoop集群之上。Hive使用了一种类似于SQL的语言，叫作Hive Query语言 ( Hive Query Language, HQL），这使得在Hadoop系统中查询和处理数据变得非常容易。Hive抽象了用Java等编码语言编写程序来执行分析作业的复杂性。")]),a._v(" "),_("li",[_("strong",[a._v("HBase")]),a._v("是作为开源Hadoop项目的一部分开发的NoSQL数据库。HBase运行在HDFS上，为Hadoop生态系统提供非关系型数据库。HBase有助于将大量数据压缩并以列式格式存储。同时，它还提供了快速查找功能，因为其中很大一部分数据被缓存在内存中，集群实例存储也同时在使用。")]),a._v(" "),_("li",[a._v("Presto是一个类似Hive的查询引擎，它的速度更快。它支持ANSI SQL标准，该标准很容易学习。Presto支特复杂的查询、连接和聚合功能。与Hive或MapReduce不同，Presto在内存中执行查询，减少了延迟，提高了查询性能。")]),a._v(" "),_("li",[_("strong",[a._v("Amazon Elastic MapReduce (EMR）")]),a._v(" 本质上是云上的Hadoop。你可以使用EMR来发挥Hadoop框架与AWS云的强大功能。EMR支持所有最流行的开源框架，包括Apache Spark、Hive、Pig、 Presto、Impala、HBase等。EMR提供了解轉的计算和存储，这意味着不必让大型的Hadoop集群持续运转，我们可以执行数据转换并将结果加载到持久化的Amazon S3存储中，然后关闭服务器。")]),a._v(" "),_("li",[_("strong",[a._v("AWS Glue")]),a._v("是一个托管的ETL服务，它有助于实现数据处理、登记和机器学习转换以查找重复记录。AWS Glue数据目录与Hive数据目录兼容，并在各种数据源（包括关系型数据库、NOSQL和文件）间提供集中的元数据存储库。AWS Glue建立在Spark集群之上，并将ETL作为一项托管服务提供。AWS Glue可为常见的用例生成PySpark和Scala代码，因此不需要从头开始编写ETL代码。Clue作业授权功能可处理作业中的任何错误，并提供日志以了解底层权限或数据格式问题。Glue提供了工作流，通过简单的拖放功能就能够帮助我们建立自动化的数据流水线。")])]),a._v(" "),_("h2",{attrs:{id:"数据可视化"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#数据可视化"}},[a._v("#")]),a._v(" 数据可视化")]),a._v(" "),_("p",[a._v("数据洞见用来解答重要的业务问题，数据流水线从不同的平台采集了大量的数据，数据可视化可以帮助我们根据业务需求准备可视化的报告，流行的可视化平台有：")]),a._v(" "),_("ul",[_("li",[_("strong",[a._v("Amazon QuickSight")]),a._v("是一个基于云的BI工具，用于企业级数据可视化。它自带各种预设好的可视化图形，如线图、饼图、树状图、热图、直方图等。Amazon Quicksight拥有一个可并行的内存计算引擎，能够快速這染可视化视图。它还可以执行数据准备任务，如重命名和删除字段，更改数据类型，将计算结果设置为新字段。QuickSight还提供了基于机器学习的可视化洞见和其他基于机器学习的功能，如自动预测。")]),a._v(" "),_("li",[_("strong",[a._v("Kibana")]),a._v("是一个开源的数据可视化工具，用于流数据可视化和日志探索。Kibana可以和Elasticsearch深度集成，Elasticsearch更是将其作为默认选项，在其上提供数据搜索服务。与其他BI工具一样，Kibana也提供了常见的可视化图，如直方图、饼图和热图，同时还提供了内置的地理空间支持")]),a._v(" "),_("li",[_("strong",[a._v("Tableau")]),a._v("是最流行的BI工具之一，用于数据可视化。它使用了可视化查询引擎，其速度比传统查询更快。Tableau提供了拖放用户界面，并且能够混合来自多个数据源的数据。")]),a._v(" "),_("li",[_("strong",[a._v("PowerBI")]),a._v("是微软提供的一个流行的BI工具。它提供了包括多种可视化选择的自助式分析功能。")])]),a._v(" "),_("p",[a._v("数据可视化是一个必要且庞大的课题，我们需要了解各种可用的工具，并根据业务中数据可视化的需求做出正确的选择。")]),a._v(" "),_("h2",{attrs:{id:"机器学习"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#机器学习"}},[a._v("#")]),a._v(" 机器学习")]),a._v(" "),_("p",[a._v("机器学习就是与数据打交道。训练数据和标签的质量对ML模型的成功至关重要。高质量的数据能让ML模型更准确，预测更正确。在现实世界中，数据往往存在多种问题，如缺失值、噪声、偏差、离群值等。数据科学的部分作用就是对数据进行清洗，让它为机器学习做好准备。")]),a._v(" "),_("p",[a._v("要进行数据准备，首先要了解业务问题。如果对业务问题没有清晰的理解，那么获得的任何洞见都有可能无法解决问题。在切实理解业务问题之后，我们可以开始缩小机器学习问题类别的范国，并确定机器学习是否适合解决特定业务问题。")]),a._v(" "),_("p",[a._v("数据科学包括数据收集、分析、预处理和特征工程。探索数据为我们提供了必要的信息，如数据质量和清洁度、数据中有趣的模式，以及开始建模后可能的前进路径。")]),a._v(" "),_("p",[_("img",{attrs:{src:"https://i.bmp.ovh/imgs/2022/06/06/a5a1c0f4e4129dca.png",alt:""}})]),a._v(" "),_("ul",[_("li",[_("strong",[a._v("预处理")]),a._v("：数据科学家对数据进行预处理，并将其划分为训练、验证和测试数据集。ML模型使用训练数据集进行训练，并使用验证数据集进行评估。一旦模型就绪，就可以使用测试数据集来测试它。考虑到数据量和业务用例，一般需要将数据划分为训练集、测试集和验证集，可以将70%的数据用于训练，10%用于验证，20%用于测试。特征是数据集的独立属性，它可能影响也可能不影响结果。特征工程是为了找到正确的特征，它可以帮助提高模型的淮确性。标签是我们的目标结果，它取决于特征选择。为了选择正确的特征，我们可以采取降维的方式从数据中过滤和提取最有效的特征。")]),a._v(" "),_("li",[_("strong",[a._v("学习")]),a._v("：在学习阶段，要根据业务用例和数据选择合适的机器学习算法。学习阶段是机器学习流程中的核心，会在训练数据集上训练ML模型。为了获得精准的模型，我们需要对各种参数进行实验，并进行模型选择。")]),a._v(" "),_("li",[_("strong",[a._v("评估")]),a._v("：一旦ML模型在学习阶段得到训练，就要用已知的数据集来评估其准确性。使用预处理阶段保留的验证数据集来评估模型。如型预测精度没有达到可分辦验证数据确定的异常的程度，则需要根据评估结果对模型进行必要的调整。")]),a._v(" "),_("li",[_("strong",[a._v("预测")]),a._v("：评估完成后，即可部署模型并进行预测。这些预测可以实时进行，也可以按批次进行，我们要考虑到过拟合和欠拟合的问题，才能得到正确的答案。")])]),a._v(" "),_("p",[a._v("机器学习算法可以分为监督学习和无监督学习，在监督学习中，算法会获得一组训练示例，其中数据和目标是已知的。它可以预测包含同样属性的新数据集的目标值。对于监督算法，需要人工干预和验证，例如，对照片进行分类和标记。在无监督学习中，算法会得到大量数据，它必须找到数据之间的模式和关系。它可以从数据集中得出推论。在无监督学习中，不需要人工\n干预，例如，它根据上下文对文档进行自动分类。它解決的问题是，当训练示例无法提供正确的结果时，算法必须通过聚类找到数据中的模式。")])])}),[],!1,null,null,null);v.default=s.exports}}]);